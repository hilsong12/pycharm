# -*- coding: utf-8 -*-
"""AI_exam01_introduction_of_Deeplearning.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1nSLx4kModyqWAPNVruWjqqSBearmUL0-

##딥러닝 입문

###Linear regression

기존의 프로그래밍 방식
"""

def celsius_to_fahrenheit(x):
    return x* 1.8 + 32

celsius_value = int(input('섭씨온도를 입력하세요. :'))
print('화씨온도로',celsius_to_fahrenheit(celsius_value),'도 입니다.' )

"""##딥러닝 방식"""

# 텐서플로 Keras에서 순차형 모델(Sequential)을 사용하기 위한 클래스
from tensorflow.keras.models import Sequential

# Dense(완전연결 레이어), InputLayer(입력 형태 지정용 레이어) 불러오기
from tensorflow.keras.layers import Dense, InputLayer

# NumPy: 수치 계산 라이브러리
# np라는 짧은 이름으로 사용하여 코드 가독성을 높임
import numpy as np

# Matplotlib: 데이터 시각화 라이브러리
# plt라는 이름으로 간단히 그래프를 그릴 수 있도록 설정
import matplotlib.pyplot as plt

data_C = np.array(range(0,100))   #넘파이라는 어레이의 생성자를 이용해 배열을 만듬  #리스트와 달리 행렬연산이 된다. ,도 없다.
data_F= celsius_to_fahrenheit(data_C)
print(data_C)
print(data_F)



# (1) Sequential 모델 생성
# Sequential: 층(layer)을 위에서 아래로 순차적으로 쌓는 가장 단순한 모델
model = Sequential()

# (2) 입력층(InputLayer) 추가
# input_shape=(1,) → 입력 데이터가 '특징 1개짜리'라는 의미
# 예) 섭씨온도 1개 값을 입력으로 받는 형태
model.add(InputLayer(input_shape=(1,)))

# (3) Dense 레이어 추가 (출력층)
# Dense(1): 뉴런 1개를 가진 완전연결(FC) 레이어
# 이 모델은 결국 y = Wx + b 형태의 1차 함수(직선)를 학습함
model.add(Dense(1))

# (4) 모델 컴파일
# loss='mse'     → 평균제곱오차(MSE), 회귀(regression)에 적합한 손실 함수
# optimizer='rmsprop' → RMSProp 옵티마이저, 파라미터를 업데이트하는 방식
model.compile(loss='mse', optimizer='rmsprop')

# (5) 모델 구조 요약 출력
# 레이어 이름, 출력 형태, 파라미터 수 등을 표로 확인할 수 있음
model.summary()

scaled_data_C = data_C/100
scaled_data_F = data_F/100   #100분의 1로 스케일링 했다. 모델한테 줄때는 모델이 학습하기 좋도록 전처리를 해야한다.
print(scaled_data_C)
print(scaled_data_F)

# 모델에 입력값 0.01을 넣어 예측 결과를 출력
# np.array([0.01]) → 모델 입력 형태에 맞게 NumPy 배열로 변환
# model.predict(...) → 학습된 모델이 출력값(예측값)을 계산
print(model.predict(np.array([0.01])))

# 현재 모델(구조 + 가중치 + 옵티마이저 상태)을 HDF5 파일 형식(.h5)으로 저장
# 'before_learning.h5' → 저장될 파일 이름
# 이 파일은 추후 model.load_model()로 그대로 복구하여 다시 사용할 수 있음
model.save('before_learning.h5')

# 모델 학습 실행
# scaled_data_C → 입력 데이터 (특징 1개: 스케일된 섭씨)
# scaled_data_F → 정답 데이터 (스케일된 화씨)
# epochs=1000 → 전체 데이터를 1000번 반복하여 학습
# 반환값 fit_hist에는 각 epoch마다의 손실 값(loss)이 기록됨
fit_hist = model.fit(scaled_data_C, scaled_data_F, epochs=1000)

plt.plot(fit_hist.history['loss'])
plt.show()

print(model.predict(np.array([0.01])))

model.save('after_learning.h5')

import h5py

def show(name, obj):
    print(name)

with h5py.File('after_learning.h5', 'r') as f:
    f.visititems(show)

import h5py

filename = "after_learning.h5"

# (1) HDF5 파일을 읽기 모드('r')로 엶
#     이 파일에는 학습된 모델의 가중치와 구조 정보가 저장되어 있음
with h5py.File(filename, 'r') as f:

    # (2) 최상위 그룹(=루트)의 키 목록 출력
    #     보통 'model_weights', 'optimizer_weights' 등이 있음
    print(list(f.keys()))

    # (3) 학습된 Dense 레이어의 kernel(가중치) 접근
    #     경로: model_weights → dense_1 → sequential_2 → dense_1 → kernel
    #     kernel은 (입력, 출력) 형태의 가중치 행렬
    print(list(f['model_weights']['dense']['sequential']['dense']['kernel']))

    # (4) 학습된 Dense 레이어의 bias(편향) 접근
    #     경로: model_weights → dense_1 → sequential_2 → dense_1 → bias
    #     bias는 1차원 배열 형태로 출력 뉴런 수만큼 존재
    print(list(f['model_weights']['dense']['sequential']['dense']['bias']))

import h5py

filename = 'before_learning.h5'

with h5py.File(filename, 'r') as f:
    print(list(f['model_weights']['dense']['sequential']['dense']['kernel']))
    print(list(f['model_weights']['dense']['sequential']['dense']['bias']))



import h5py

celsius_value = int(input('섭씨온도를 입력하세요. :'))
print('화씨온도로', (model.predict(np.array([celsius_value/100]))*100)[0][0],'도 입니다.' )

noise = np.random.normal(0,0.05,100)   #랜덤 정규분포 표준편차 0.05
print(noise)

# 노이즈가 추가된 결과를 저장할 빈 NumPy 배열 생성
noised_scaled_data_F = np.array([])

# scaled_data_F의 각 데이터(data)에 대해 반복
for data in scaled_data_F:

    # 평균 0, 표준편차 0.05인 정규분포 노이즈 100개 생성 후, data 값에 더함
    # 결과: 해당 data를 중심으로 퍼져 있는 100개의 노이즈 데이터 생성
    noise = np.random.normal(0, 0.05, 100) + data

    # 기존 배열에 새로 생성된 noise 데이터를 이어붙임 (1차원으로 연결)
    noised_scaled_data_F = np.append(noised_scaled_data_F, noise)

# 완성된 전체 노이즈 데이터 출력
print(noised_scaled_data_F)

# 전체 데이터 개수 출력
# = len(scaled_data_F) * 100
print(len(noised_scaled_data_F))

# 노이즈가 적용된 C값(입력 값)을 모을 리스트 초기화
noised_scaled_data_C = []

# 0부터 99까지 반복 (총 100개의 원본 데이터)
for data in range(100):

    # 각 숫자(data)를 100번 반복하여 리스트에 추가
    # 결과적으로 각 숫자당 100개의 동일한 값이 들어감
    for i in range(100):
        noised_scaled_data_C.append(data)

# 리스트를 NumPy 배열로 변환 (연산을 위해 필요)
noised_scaled_data_C = np.array(noised_scaled_data_C)

# 0~99 까지의 값을 100으로 나누어 0.00 ~ 0.99 범위로 스케일링
noised_scaled_data_C = noised_scaled_data_C / 100

# 결과 확인
print(noised_scaled_data_C)

# 전체 데이터 개수 출력 (100개 * 100회 = 10,000개)
print(len(noised_scaled_data_C))

# (1) 새 Figure 객체 생성
# figsize=(50,50)은 그래프 크기를 인치 단위로 지정 (매우 큰 그림)
fig = plt.figure(figsize=(25, 25))

# (2) 1행 1열의 서브플롯(전체 화면)을 하나 생성하고, ax 변수로 받음
ax = fig.add_subplot(111)

# (3) 산점도(scatter plot) 그리기
# x축: noised_scaled_data_C  (입력 값, 스케일링된 섭씨)
# y축: noised_scaled_data_F  (출력 값, 노이즈가 포함된 화씨)
# alpha=0.2 → 점의 투명도 (0=완전투명, 1=불투명)
# s=200   → 점의 크기
# marker='+' → 점 모양 지정
ax.scatter(noised_scaled_data_C, noised_scaled_data_F, alpha=0.2, s=200, marker='+')

# (4) 완성된 그래프 화면에 표시
plt.show()

model1= Sequential()
model1.add(InputLayer(input_shape=(1,)))
model1.add(Dense(1))
model1.compile(loss='mse', optimizer='rmsprop')  #mean square error
model1.summary()

fit_hist = model1.fit(noised_scaled_data_C, noised_scaled_data_F , epochs= 20)

model1.save('noised_after_learning.h5')

import h5py

filename = 'noised_after_learning.h5'

with h5py.File(filename, 'r') as f:
    print(list(f.keys()))
    print(list(f['model_weights']['dense_1']['sequential_1']['dense_1']['kernel']))
    print(list(f['model_weights']['dense_1']['sequential_1']['dense_1']['bias']))

plt.plot(fit_hist.history['loss'])
plt.show()

